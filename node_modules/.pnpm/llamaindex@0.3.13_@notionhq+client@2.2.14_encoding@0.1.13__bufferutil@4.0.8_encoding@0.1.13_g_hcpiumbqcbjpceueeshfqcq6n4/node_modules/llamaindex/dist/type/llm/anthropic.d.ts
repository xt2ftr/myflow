import type { ClientOptions } from "@anthropic-ai/sdk";
import { Anthropic as SDKAnthropic } from "@anthropic-ai/sdk";
import type { Tool, ToolsBetaMessageParam } from "@anthropic-ai/sdk/resources/beta/tools/messages";
import type { MessageParam } from "@anthropic-ai/sdk/resources/messages";
import type { BaseTool } from "../types.js";
import { ToolCallLLM } from "./base.js";
import type { ChatMessage, ChatResponse, ChatResponseChunk, LLMChatParamsNonStreaming, LLMChatParamsStreaming, ToolCallLLMMessageOptions } from "./types.js";
export declare class AnthropicSession {
    anthropic: SDKAnthropic;
    constructor(options?: ClientOptions);
}
/**
 * Get a session for the Anthropic API. If one already exists with the same options,
 * it will be returned. Otherwise, a new session will be created.
 * @param options
 * @returns
 */
export declare function getAnthropicSession(options?: ClientOptions): AnthropicSession;
export declare const ALL_AVAILABLE_ANTHROPIC_LEGACY_MODELS: {
    "claude-2.1": {
        contextWindow: number;
    };
    "claude-instant-1.2": {
        contextWindow: number;
    };
};
export declare const ALL_AVAILABLE_V3_MODELS: {
    "claude-3-opus": {
        contextWindow: number;
    };
    "claude-3-sonnet": {
        contextWindow: number;
    };
    "claude-3-haiku": {
        contextWindow: number;
    };
};
export declare const ALL_AVAILABLE_ANTHROPIC_MODELS: {
    "claude-3-opus": {
        contextWindow: number;
    };
    "claude-3-sonnet": {
        contextWindow: number;
    };
    "claude-3-haiku": {
        contextWindow: number;
    };
    "claude-2.1": {
        contextWindow: number;
    };
    "claude-instant-1.2": {
        contextWindow: number;
    };
};
export type AnthropicAdditionalChatOptions = {};
export declare class Anthropic extends ToolCallLLM<AnthropicAdditionalChatOptions> {
    model: keyof typeof ALL_AVAILABLE_ANTHROPIC_MODELS;
    temperature: number;
    topP: number;
    maxTokens?: number;
    apiKey?: string;
    maxRetries: number;
    timeout?: number;
    session: AnthropicSession;
    constructor(init?: Partial<Anthropic>);
    get supportToolCall(): boolean;
    get metadata(): {
        model: "claude-3-opus" | "claude-3-sonnet" | "claude-3-haiku" | "claude-2.1" | "claude-instant-1.2";
        temperature: number;
        topP: number;
        maxTokens: number | undefined;
        contextWindow: number;
        tokenizer: undefined;
    };
    getModelName: (model: string) => string;
    formatMessages<Beta = false>(messages: ChatMessage<ToolCallLLMMessageOptions>[]): Beta extends true ? ToolsBetaMessageParam[] : MessageParam[];
    chat(params: LLMChatParamsStreaming<AnthropicAdditionalChatOptions, ToolCallLLMMessageOptions>): Promise<AsyncIterable<ChatResponseChunk<ToolCallLLMMessageOptions>>>;
    chat(params: LLMChatParamsNonStreaming<AnthropicAdditionalChatOptions, ToolCallLLMMessageOptions>): Promise<ChatResponse<ToolCallLLMMessageOptions>>;
    protected streamChat(messages: ChatMessage<ToolCallLLMMessageOptions>[], systemPrompt?: string | null): AsyncIterable<ChatResponseChunk<ToolCallLLMMessageOptions>>;
    static toTool(tool: BaseTool): Tool;
}
