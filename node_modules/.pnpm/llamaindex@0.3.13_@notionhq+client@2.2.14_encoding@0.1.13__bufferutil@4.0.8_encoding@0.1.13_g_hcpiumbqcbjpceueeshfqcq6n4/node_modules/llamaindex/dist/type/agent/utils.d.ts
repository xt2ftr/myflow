/// <reference types="node" resolution-mode="require"/>
import { ReadableStream } from "@llamaindex/env";
import type { Logger } from "../internal/logger.js";
import type { ChatMessage, ChatResponseChunk, PartialToolCall, TextChatMessage, ToolCall } from "../llm/index.js";
import type { BaseTool, ToolOutput } from "../types.js";
export declare function callTool(tool: BaseTool | undefined, toolCall: ToolCall | PartialToolCall, logger: Logger): Promise<ToolOutput>;
export declare function consumeAsyncIterable<Options extends object>(input: ChatMessage<Options>, previousContent?: string): Promise<ChatMessage<Options>>;
export declare function consumeAsyncIterable<Options extends object>(input: AsyncIterable<ChatResponseChunk<Options>>, previousContent?: string): Promise<TextChatMessage<Options>>;
export declare function createReadableStream<T>(asyncIterable: AsyncIterable<T>): ReadableStream<T>;
