"use strict";
Object.defineProperty(exports, "__esModule", {
    value: true
});
Object.defineProperty(exports, "MultiModalResponseSynthesizer", {
    enumerable: true,
    get: function() {
        return MultiModalResponseSynthesizer;
    }
});
const _Node = require("../Node.js");
const _Response = require("../Response.js");
const _Settings = require("../Settings.js");
const _index = require("../embeddings/index.js");
const _Mixin = require("../prompts/Mixin.js");
const _Prompt = require("./../Prompt.js");
class MultiModalResponseSynthesizer extends _Mixin.PromptMixin {
    serviceContext;
    metadataMode;
    textQATemplate;
    constructor({ serviceContext, textQATemplate, metadataMode } = {}){
        super();
        this.serviceContext = serviceContext;
        this.metadataMode = metadataMode ?? _Node.MetadataMode.NONE;
        this.textQATemplate = textQATemplate ?? _Prompt.defaultTextQaPrompt;
    }
    _getPrompts() {
        return {
            textQATemplate: this.textQATemplate
        };
    }
    _updatePrompts(promptsDict) {
        if (promptsDict.textQATemplate) {
            this.textQATemplate = promptsDict.textQATemplate;
        }
    }
    async synthesize({ query, nodesWithScore, stream }) {
        if (stream) {
            throw new Error("streaming not implemented");
        }
        const nodes = nodesWithScore.map(({ node })=>node);
        const nodeMap = (0, _Node.splitNodesByType)(nodes);
        const imageNodes = nodeMap[_Node.ModalityType.IMAGE] ?? [];
        const textNodes = nodeMap[_Node.ModalityType.TEXT] ?? [];
        const textChunks = textNodes.map((node)=>node.getContent(this.metadataMode));
        // TODO: use builders to generate context
        const context = textChunks.join("\n\n");
        const textPrompt = this.textQATemplate({
            context,
            query
        });
        const images = await Promise.all(imageNodes.map(async (node)=>{
            return {
                type: "image_url",
                image_url: {
                    url: await (0, _index.imageToDataUrl)(node.image)
                }
            };
        }));
        const prompt = [
            {
                type: "text",
                text: textPrompt
            },
            ...images
        ];
        const llm = (0, _Settings.llmFromSettingsOrContext)(this.serviceContext);
        const response = await llm.complete({
            prompt
        });
        return new _Response.Response(response.text, nodesWithScore);
    }
}
